import streamlit as st
import pandas as pd
import joblib
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans
from kmodes.kmodes import KModes

# Configuraci√≥n de la p√°gina
st.set_page_config(page_title="App de An√°lisis y Predicci√≥n de Ventas", layout="wide")

# Cargar modelo de predicci√≥n Holt-Winters
fit = joblib.load("modelo_holt.pkl")

# Cargar datos originales
df = pd.read_csv(r"C:\Users\ju444\OneDrive\Documents\Proyecto Analitica 2025-1\Video_Games_Sales_as_at_22_Dec_2016 (1).csv")


# Preprocesamiento: generar columna de fecha desde el a√±o de lanzamiento
df = df[df["Year_of_Release"].notna()].copy()
df["Year_of_Release"] = df["Year_of_Release"].astype(int)
df["Fecha"] = pd.to_datetime(df["Year_of_Release"].astype(str) + "-01-01", errors="coerce")

# Crear pesta√±as
tab1, tab2, tab3, tab4, tab5 = st.tabs(["üîÆ Predicciones", "üìä Estad√≠sticas Descriptivas", "üåé Ventas por Regi√≥n", "Validaci√≥n del Modelo y Visualizaci√≥n del Error","An√°lisis de Clustering"])

# ----- PESTA√ëA 1: Predicciones -----
# ----- PESTA√ëA 1: Predicciones + Cargar nuevos datos -----
with tab1:
    st.header("üîÆ Predicci√≥n de ventas por trimestres")

    trimestres = st.number_input("¬øCu√°ntos trimestres deseas predecir?", min_value=1, max_value=200, value=4)

    if st.button("Predecir"):
        ultima_fecha = pd.to_datetime("2020-04-01")  # Ajusta seg√∫n tu serie entrenada
        fechas_futuras = pd.date_range(start=ultima_fecha + pd.offsets.QuarterEnd(1), periods=trimestres, freq="Q")
        pronostico = fit.forecast(trimestres)

        resultado = pd.DataFrame({
            "Fecha": fechas_futuras,
            "Pron√≥stico": pronostico
        })

        st.write("### Resultados del pron√≥stico:")
        st.dataframe(resultado)

        fig, ax = plt.subplots(figsize=(10, 5))
        ax.plot(resultado["Fecha"], resultado["Pron√≥stico"], marker="o", linestyle="-", color="green")
        ax.set_title("Pron√≥stico de Ventas por Trimestre")
        ax.set_xlabel("Fecha")
        ax.set_ylabel("Ventas (en millones)")
        ax.set_ylim(resultado["Pron√≥stico"].min() * 0.95, resultado["Pron√≥stico"].max() * 1.05)
        ax.grid(True)
        st.pyplot(fig)

    st.markdown("---")
    st.header("üì• Agregar nuevos datos hist√≥ricos")

    uploaded_file = st.file_uploader("Sube un nuevo archivo CSV con datos hist√≥ricos", type=["csv"])

    if uploaded_file is not None:
        nuevos_datos = pd.read_csv(uploaded_file)
        st.write("Vista previa de los nuevos datos:")
        st.dataframe(nuevos_datos.head())

        if st.button("Agregar y actualizar dataset"):
            # Asegurarse de que la columna 'Year_of_Release' existe
            if "Year_of_Release" not in nuevos_datos.columns:
                st.error("El archivo debe contener una columna 'Year_of_Release'")
            else:
                nuevos_datos = nuevos_datos[nuevos_datos["Year_of_Release"].notna()].copy()
                nuevos_datos["Year_of_Release"] = nuevos_datos["Year_of_Release"].astype(int)
                nuevos_datos["Fecha"] = pd.to_datetime(nuevos_datos["Year_of_Release"].astype(str) + "-01-01", errors="coerce")

                # Leer el archivo actual
                df_actual = pd.read_csv(r"C:\Users\ju444\OneDrive\Documents\Proyecto Analitica 2025-1\Video_Games_Sales_as_at_22_Dec_2016 (1).csv")
                df_actual["Year_of_Release"] = df_actual["Year_of_Release"].fillna(0).astype(int)
                df_actual["Fecha"] = pd.to_datetime(df_actual["Year_of_Release"].astype(str) + "-01-01", errors="coerce")

                # Concatenar y eliminar duplicados
                df_actualizado = pd.concat([df_actual, nuevos_datos], ignore_index=True)
                df_actualizado.drop_duplicates(inplace=True)

                # Guardar el nuevo dataset
                df_actualizado.to_csv(r"C:\Users\ju444\OneDrive\Documents\Proyecto Analitica 2025-1\Video_Games_Sales_as_at_22_Dec_2016 (1).csv", index=False)
                st.success("‚úÖ Datos a√±adidos correctamente. Por favor, reinicia la app para aplicar los cambios.")

                # Opci√≥n para reentrenar el modelo (solo si quieres automatizarlo m√°s)
                # Podr√≠as integrar aqu√≠ el reentrenamiento de Holt-Winters si lo deseas.


# ----- PESTA√ëA 2: Estad√≠sticas Descriptivas -----
with tab2:
    st.header("üìä Estad√≠sticas Descriptivas del Dataset")

    st.subheader("Vista previa de los datos")
    st.dataframe(df.head())

    st.subheader("Descripci√≥n estad√≠stica")
    st.write(df.describe())
    st.write("Esta tabla muestra un resumen num√©rico de las variables del conjunto de datos, como el promedio, los valores m√°ximos y m√≠nimos, y los percentiles. Es √∫til para conocer la distribuci√≥n de los datos.")

    st.subheader("Ventas por regi√≥n")
    regiones = ["NA_Sales", "EU_Sales", "JP_Sales", "Other_Sales", "Global_Sales"]
    fig, ax = plt.subplots(figsize=(10, 5))
    df[regiones].sum().plot(kind="bar", ax=ax)
    ax.set_ylabel("Ventas en millones")
    ax.set_title("Ventas totales por regi√≥n")
    st.pyplot(fig)
    st.write("Este gr√°fico compara las ventas totales de videojuegos en diferentes regiones: Norteam√©rica, Europa, Jap√≥n, Otros y Ventas Globales. De acuerdo con los datos, Norteam√©rica es la regi√≥n con las mayores ventas, destac√°ndose significativamente sobre las dem√°s con una participaci√≥n dominante en el mercado global. Esto refleja la gran demanda de videojuegos en esta regi√≥n y su influencia en la industria. En contraste, Jap√≥n y la categor√≠a de Otros presentan las ventas m√°s bajas, lo que podr√≠a estar relacionado con diferentes factores como las preferencias culturales o la oferta limitada de ciertos g√©neros en estas regiones. Aunque Jap√≥n sigue siendo un mercado importante en t√©rminos de desarrollo de videojuegos, su volumen de ventas globales es menor comparado con Norteam√©rica y Europa.")

    st.subheader("G√©neros m√°s vendidos")
    top_generos = df.groupby("Genre")["Global_Sales"].sum().sort_values(ascending=False)
    fig, ax = plt.subplots(figsize=(10, 5))
    top_generos.plot(kind="bar", ax=ax)
    ax.set_ylabel("Ventas globales")
    ax.set_title("Ventas globales por g√©nero")
    st.pyplot(fig)
    st.write("Este gr√°fico proporciona una visi√≥n clara sobre los g√©neros de videojuegos que han generado mayores ventas a nivel global, lo cual es esencial para entender las tendencias y preferencias del mercado. El g√©nero de acci√≥n lidera las ventas con un impresionante total superior a los 1500 millones de unidades, lo que refleja su popularidad y la continua demanda de t√≠tulos intensos y din√°micos. En segundo lugar, se encuentran los g√©neros de deportes y disparos, que tambi√©n muestran un rendimiento fuerte, con ventas considerables en ambas categor√≠as, se√±alando la preferencia por experiencias competitivas y de acci√≥n. Por otro lado, el g√©nero de estrategia se encuentra entre los menos vendidos, lo que podr√≠a sugerir que, aunque tiene una base de jugadores leales, no alcanza el nivel de popularidad de otros g√©neros. Este an√°lisis permite identificar √°reas de oportunidad para el desarrollo de nuevos juegos y ajustar estrategias de marketing de acuerdo con los intereses actuales de los jugadores.")

# ----- PESTA√ëA 3: Clustering de ventas por regi√≥n -----
with tab3:
    st.header("üåç Agrupaci√≥n de Pa√≠ses por Ventas (KMeans)")

    # Crear tabla resumida con ventas por regi√≥n
    regiones = ["NA_Sales", "EU_Sales", "JP_Sales", "Other_Sales"]
    df_region = pd.DataFrame(df[regiones].sum()).reset_index()
    df_region.columns = ["Region", "Ventas"]

    # Aplicar clustering
    k = st.slider("Selecciona el n√∫mero de clusters", 2, 4, 2)
    kmeans = KMeans(n_clusters=k, random_state=42)
    df_region["Cluster"] = kmeans.fit_predict(df_region[["Ventas"]])

    st.subheader("Resultados del Clustering")
    st.dataframe(df_region)

    st.subheader("Ventas por Regi√≥n (Clusterizado)")
    fig, ax = plt.subplots(figsize=(8, 4))
    sns.barplot(data=df_region, x="Region", y="Ventas", hue="Cluster", dodge=False, ax=ax)
    plt.title("Clustering de regiones seg√∫n ventas")
    st.pyplot(fig)
    import streamlit as st
    import pandas as pd
    import numpy as np
    from sklearn.preprocessing import StandardScaler, LabelEncoder
    from sklearn.decomposition import PCA
    from sklearn.cluster import KMeans
    from kmodes.kprototypes import KPrototypes
    import matplotlib.pyplot as plt

    @st.cache_data
    def preprocess_pca_kmeans(df, num_cols, k=2):
        df_clean = df[num_cols].dropna()
        scaler = StandardScaler()
        df_scaled = scaler.fit_transform(df_clean)

        pca = PCA(n_components=2)
        df_pca = pca.fit_transform(df_scaled)
        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
        clusters = kmeans.fit_predict(df_pca)

        df_plot = pd.DataFrame(df_pca, columns=["PC1", "PC2"])
        df_plot["Cluster"] = clusters
        return df_plot

    def preprocess_kprototypes(df, cat_cols, num_cols, k=2):
        # Check for missing values and handle them
        df_kp = df[cat_cols + num_cols].dropna().copy()
    
        # Encode categorical columns using LabelEncoder
        for col in cat_cols:
            df_kp[col] = LabelEncoder().fit_transform(df_kp[col].astype(str))
    
        # Standardize numerical columns
        df_kp[num_cols] = StandardScaler().fit_transform(df_kp[num_cols])
    
        # Prepare data for KPrototypes
        matrix = df_kp[num_cols + cat_cols].values
    
        # Fit the KPrototypes model
        kproto = KPrototypes(n_clusters=k, init='Huang', random_state=42, n_jobs=-1)
        clusters = kproto.fit_predict(matrix, categorical=[len(num_cols) + i for i in range(len(cat_cols))])
    
        # Perform PCA for visualization
        pca = PCA(n_components=2)
        df_pca = pca.fit_transform(df_kp[num_cols])
    
        # Prepare the dataframe for visualization
        df_plot = pd.DataFrame(df_pca, columns=["PC1", "PC2"])
        df_plot["Cluster"] = clusters
    
        return df_plot
          



with tab4:
    st.header("Validaci√≥n del Modelo y Visualizaci√≥n del Error")
    from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error
    import numpy as np

    # Sup√≥n que entrenaste con esta columna:
    ventas_historicas = df.groupby("Fecha")["Global_Sales"].sum().sort_index()
    pred = fit.fittedvalues

    st.subheader("Evaluaci√≥n del modelo Holt-Winters")
    fig, ax = plt.subplots(figsize=(10, 4))
    ax.plot(ventas_historicas.index, ventas_historicas.values, label="Ventas reales")
    ax.plot(pred.index, pred.values, label="Predicciones Holt-Winters", linestyle="--")
    ax.set_title("Ajuste del modelo en datos hist√≥ricos")
    ax.legend()
    st.pyplot(fig)

    # Ensure both arrays have the same length (as previously explained)
    if len(ventas_historicas) != len(pred):
        min_length = min(len(ventas_historicas), len(pred))
        ventas_historicas = ventas_historicas[:min_length]
        pred = pred[:min_length]

    # Optionally, remove NaN values if any
    mask = ~np.isnan(ventas_historicas) & ~np.isnan(pred)
    ventas_historicas = ventas_historicas[mask]
    pred = pred[mask]

    # Calculate MAPE and RMSE
    mape = mean_absolute_percentage_error(ventas_historicas, pred)
    rmse = np.sqrt(mean_squared_error(ventas_historicas, pred))
    st.markdown(f"- **MAPE**: {mape:.2%}")
    st.markdown(f"- **RMSE**: {rmse:.2f} millones")

with tab5:
    st.header("An√°lisis de Clustering")
    cluster_method = st.selectbox("Selecciona el tipo de clustering:", ["K-Means (PCA num√©ricas)", "K-Prototypes (Mixto)"])

    if cluster_method == "K-Means (PCA num√©ricas)":
        num_cols = ['NA_Sales', 'EU_Sales', 'JP_Sales', 'Other_Sales', 'Global_Sales',
                    'Critic_Score', 'Critic_Count', 'User_Score', 'User_Count']
        df_plot = preprocess_pca_kmeans(df, num_cols)
        st.write("Visualizaci√≥n con PCA y clustering K-Means")
        fig, ax = plt.subplots()
        scatter = ax.scatter(df_plot["PC1"], df_plot["PC2"], c=df_plot["Cluster"], cmap="viridis", alpha=0.6)
        plt.colorbar(scatter, ax=ax, label="Cluster")
        st.pyplot(fig)

    elif cluster_method == "K-Prototypes (Mixto)":
        cat_cols = ["Platform", "Genre", "Publisher"]
        num_cols = ["Year_of_Release", "NA_Sales", "EU_Sales", "JP_Sales", "Other_Sales"]
        df_plot = preprocess_kprototypes(df, cat_cols, num_cols)
        st.write("Visualizaci√≥n con PCA (num√©ricas) y clustering K-Prototypes")
        fig, ax = plt.subplots()
        scatter = ax.scatter(df_plot["PC1"], df_plot["PC2"], c=df_plot["Cluster"], cmap="viridis", alpha=0.6)
        plt.colorbar(scatter, ax=ax, label="Cluster")
        st.pyplot(fig)